{"cells":[{"cell_type":"markdown","metadata":{"id":"b0Yf4NBJUSNM"},"source":["# Створення нейронної мережі\n","\n","У цьому завданні ми створимо повнозв'язну нейронну мережу, використовуючи при цьому низькорівневі механізми tensorflow.\n","\n","Архітектура нейромережі представлена на наступному малюнку. Як бачиш, у ній є один вхідний шар, два приховані, а також вихідний шар. В якості активаційної функції у прихованих шарах буде використовуватись сигмоїда. На вихідному шарі ми використовуємо softmax.\n","\n","Частина коду зі створення мережі вже написана, тобі потрібно заповнити пропуски у вказаних місцях."]},{"cell_type":"markdown","metadata":{"id":"01rZWUu0USNQ"},"source":["## Архітектура нейронної мережі\n","\n","<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/>\n"]},{"cell_type":"markdown","metadata":{"id":"LLvIZ705Qw_V"},"source":["## Про датасет MNIST\n","\n","Дану нейромережу ми будемо вивчати на датасеті MNIST. Цей датасет являє собою велику кількість зображень рукописних цифр розміром $28 \\times 28$ пікселів. Кожен піксель приймає значення від 0 до 255.\n","\n","Як і раніше, датасет буде розділений на навчальну та тестову вибірки. При цьому ми виконаємо нормалізацію всіх зображень, щоб значення пікселів знаходилось у проміжку від 0 до 1, розділивши яскравість кожного пікселя на 255.\n","\n","Окрім того, архітектура нейронної мережі очікує на вхід вектор. У нашому ж випадку кожен об'єкт вибірки являє собою матрицю. Що ж робити? У цьому завданні ми \"розтягнемо\" матрицю $28 \\times 28$, отримавши при цьому вектор, що складається з 784 елементів.\n","\n","![MNIST Dataset](https://www.researchgate.net/profile/Steven-Young-5/publication/306056875/figure/fig1/AS:393921575309346@1470929630835/Example-images-from-the-MNIST-dataset.png)\n","\n","Більше інформації про датасет можна знайти [тут](http://yann.lecun.com/exdb/mnist/)."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"il_0_5OyUSNR","executionInfo":{"status":"ok","timestamp":1705548705667,"user_tz":480,"elapsed":5887,"user":{"displayName":"Yuriy Nikitchenko","userId":"06424287794076248218"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import random\n","import keras as K\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, accuracy_score"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"cd-1_abTUSNS","executionInfo":{"status":"ok","timestamp":1705555550566,"user_tz":480,"elapsed":401,"user":{"displayName":"Yuriy Nikitchenko","userId":"06424287794076248218"}}},"outputs":[],"source":["num_classes = 10 # загальна кількість класів, у нашому випадку це цифри від 0 до 9\n","num_features = 784 # кількість атрибутів вхідного вектора 28 * 28 = 784\n","\n","learning_rate = 0.001 # швидкість навчання нейронної мережі\n","training_steps = 3000 # максимальне число епох\n","batch_size = 256 # перераховувати ваги мережі ми будемо не на всій вибірці, а на її випадковій підмножині з batch_size елементів\n","display_step = 100 # кожні 100 ітерацій ми будемо показувати поточне значення функції втрат і точності\n","\n","n_hidden_1 = 128 # кількість нейронів 1-го шару\n","n_hidden_2 = 256 # кількість нейронів 2-го шару"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"pGTXiRyTUSNT","executionInfo":{"status":"ok","timestamp":1705555182001,"user_tz":480,"elapsed":934,"user":{"displayName":"Yuriy Nikitchenko","userId":"06424287794076248218"}}},"outputs":[],"source":["# from tensorflow.keras.datasets import mnist\n","from keras.datasets import mnist\n","\n","# Завантажуємо датасет\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Перетворюємо цілочисельні пікселі на тип float32\n","x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n","\n","# Перетворюємо матриці розміром 28x28 пікселів у вектор з 784 елементів\n","x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n","\n","# Нормалізуємо значення пікселів\n","x_train, x_test = x_train / 255., x_test / 255.\n","\n","# Перемішаємо тренувальні дані\n","train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"FkRmCQjnUSNV","executionInfo":{"status":"ok","timestamp":1705555189729,"user_tz":480,"elapsed":247,"user":{"displayName":"Yuriy Nikitchenko","userId":"06424287794076248218"}}},"outputs":[],"source":["# Створимо нейронну мережу\n","\n","class DenseLayer(tf.Module):\n","    def __init__(self, in_features, out_features, name=None):\n","        super().__init__(name=name)\n","        self.w = tf.Variable(\n","            tf.random.normal([in_features, out_features]), name=\"w\"\n","        )\n","        self.b = tf.Variable(tf.zeros([out_features]), name=\"b\")\n","\n","    def __call__(self, x, activation=0):\n","        y = tf.matmul(x, self.w) + self.b\n","        if activation != 0:\n","            return tf.nn.softmax(y)\n","        else:\n","            return tf.nn.sigmoid(y)"]},{"cell_type":"code","source":["class NN(tf.Module):\n","  def __init__(self, name=None):\n","    super().__init__(name=name)\n","    # Перший шар, який складається з 128 нейронів\n","    self.layer_1 = DenseLayer(in_features=num_features, out_features=n_hidden_1)\n","    # Другий шар, який складається з 256 нейронів\n","    self.layer_2 = DenseLayer(in_features=n_hidden_1, out_features=n_hidden_2)\n","    # Вихідний шар\n","    self.layer_3 = DenseLayer(in_features=n_hidden_2, out_features=10)\n","\n","\n","  def __call__(self, x):\n","    # Передача даних через перші два шари та вихідний шар з функцією активації softmax\n","    x = self.layer_1(x)\n","    x = self.layer_2(x)\n","    return self.layer_3(x, 1)\n"],"metadata":{"id":"9wYXAA1EhVVJ","executionInfo":{"status":"ok","timestamp":1705555192500,"user_tz":480,"elapsed":7,"user":{"displayName":"Yuriy Nikitchenko","userId":"06424287794076248218"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","execution_count":29,"metadata":{"id":"LIf3o7VAUSNV","executionInfo":{"status":"ok","timestamp":1705555195324,"user_tz":480,"elapsed":11,"user":{"displayName":"Yuriy Nikitchenko","userId":"06424287794076248218"}}},"outputs":[],"source":["# В якості функції помилки в даному випадку зручно взяти крос-ентропію\n","def cross_entropy(y_pred, y_true):\n","    # Закодувати label в one hot vector\n","    y_true = tf.one_hot(y_true, depth=num_classes)\n","\n","    # Значення передбачення, щоб уникнути помилки log(0).\n","    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n","\n","    # Обчислення крос-ентропії\n","    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n","\n","# Як метрику якості використовуємо точність\n","def accuracy(y_pred, y_true):\n","    return accuracy_score(y_true, tf.argmax(y_pred, axis=1).numpy())"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"MQeT1yatUSNW","executionInfo":{"status":"ok","timestamp":1705555730460,"user_tz":480,"elapsed":185,"user":{"displayName":"Yuriy Nikitchenko","userId":"06424287794076248218"}}},"outputs":[],"source":["# Функція навчання нейромережі\n","def train(neural_net, input_x, output_y):\n","  # Для налаштування вагів мережі будемо використовувати стохастичний градієнтний спуск\n","  optimizer = tf.optimizers.SGD(learning_rate)\n","\n","  # Активація автоматичного диференціювання\n","  with tf.GradientTape() as tape:\n","    pred = neural_net(input_x)\n","    loss = cross_entropy(pred, output_y)\n","\n","    # Отримаємо список оптимізованих параметрів   ?????\n","    # Обчислимо за ними значення градієнта   ?????\n","    grads = tape.gradient(loss, neural_net.trainable_variables)\n","\n","    # Модифікуємо параметри   ?????\n","    optimizer.apply_gradients(zip(grads, neural_net.trainable_variables))\n","\n"]},{"cell_type":"code","source":["# Створимо екземпляр нейронної мережі\n","neural_net = NN(name=\"mnist\")"],"metadata":{"id":"P0QMW9-1CyyT","executionInfo":{"status":"ok","timestamp":1705555742327,"user_tz":480,"elapsed":237,"user":{"displayName":"Yuriy Nikitchenko","userId":"06424287794076248218"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","execution_count":40,"metadata":{"id":"fnyns9lBfpQZ","executionInfo":{"status":"ok","timestamp":1705555837061,"user_tz":480,"elapsed":88248,"user":{"displayName":"Yuriy Nikitchenko","userId":"06424287794076248218"}}},"outputs":[],"source":["# Тренування мережі\n","\n","loss_history = []  # кожні display_step кроків зберігай в цьому списку поточну помилку нейромережі\n","accuracy_history = [] # кожні display_step кроків зберігай в цьому списку поточну точність нейромережі\n","\n","# У цьому циклі ми будемо проводити навчання нейронної мережі\n","# із тренувального датасета train_data вилучи випадкову підмножину, на якій\n","# відбудеться тренування. Використовуй метод take, доступний для тренувального датасета.\n","for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n","    # Оновлюємо ваги нейронної мережі\n","    train(neural_net, batch_x, batch_y)\n","\n","    if step % display_step == 0:\n","        pred = neural_net(batch_x)\n","        loss = cross_entropy(pred, batch_y)\n","        # acc = accuracy(batch_y, pred)\n","        loss_history.append(loss.numpy())\n","        # accuracy_history.append(acc)\n"]},{"cell_type":"code","source":["print(loss_history)\n","# print(accuracy_history)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_fo-RvPSwAwj","executionInfo":{"status":"ok","timestamp":1705555856116,"user_tz":480,"elapsed":264,"user":{"displayName":"Yuriy Nikitchenko","userId":"06424287794076248218"}},"outputId":"151ac385-e6af-4296-80be-85e2ec636d7d"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["[361.81165, 203.04593, 226.03535, 206.98398, 122.13726, 143.27899, 135.74004, 147.17181, 101.62924, 85.44277, 93.159004, 100.764565, 104.50152, 68.599815, 81.04555, 77.67768, 97.373604, 68.12564, 53.40531, 102.86727, 53.21087, 85.682396, 69.38661, 57.233513, 92.86499, 74.15043, 79.117096, 51.72961, 67.36467, 54.30643]\n"]}]},{"cell_type":"code","source":["test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n","test_data = test_data.repeat().shuffle(1000).batch(batch_size).prefetch(1)\n","# print(test_data[0].shape)"],"metadata":{"id":"TbDPQtdmDxx5","executionInfo":{"status":"ok","timestamp":1705563247235,"user_tz":480,"elapsed":194,"user":{"displayName":"Yuriy Nikitchenko","userId":"06424287794076248218"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# Оцінка точності на тестовому наборі\n","\n","test_accuracy = []\n","\n","for test_batch_x, test_batch_y in test_data:\n","    test_pred = neural_net(test_batch_x)\n","    test_acc = accuracy_score(test_batch_y, tf.argmax(test_pred, axis=1).numpy())\n","    test_accuracy.append(test_acc)\n","\n","test_acc = tf.reduce_mean(test_accuracy)\n","\n","print(f\"Точність на тренувальному наборі: {accuracy_history[-1]}\")\n","print(f\"Точність на тестовому наборі: {test_acc}\")"],"metadata":{"id":"OB1NOf8uv9Mx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["neural_net.submodules"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PVWqVUf7QdWJ","executionInfo":{"status":"ok","timestamp":1705458755114,"user_tz":480,"elapsed":217,"user":{"displayName":"Yuriy Nikitchenko","userId":"06424287794076248218"}},"outputId":"099f418a-2984-4ec5-dbbb-0c91d51258bc"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<__main__.DenseLayer at 0x7a74a3e67850>,\n"," <__main__.DenseLayer at 0x7a74ad12b580>,\n"," <__main__.DenseLayer at 0x7a74a3e64730>)"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_yCBfG6MbQB2"},"outputs":[],"source":["# Виведіть графіки залежності зміни точності і втрат від кроку\n","# Якщо все зроблено правильно, то точність повинна зростати, а втрати зменшуватись\n","\n","import matplotlib.pyplot as plt\n","\n","# Виведіть графік функції втрат\n","# Місце для вашого коду\n","\n","# Виведіть графік точності\n","# Місце для вашого коду\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LE3g4gDyUSNY"},"outputs":[],"source":["# Обчисліть точність навченої нейромережі\n","# Місце для вашого коду\n","# Тестування моделі на тестових даних\n","# Місце для вашого коду"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_EEHAubOUSNY"},"outputs":[],"source":["# Протестуйте навчену нейромережу на 10 зображеннях. З тестової вибірки візьміть 5\n","# випадкових зображень і передайте їх у нейронну мережу.\n","# Виведіть зображення та випишіть  поруч відповідь нейромережі.\n","# Зробіть висновок про те, чи помиляється твоя нейронна мережа, і якщо так, то як часто?\n","\n","# Місце для вашого коду\n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"}},"nbformat":4,"nbformat_minor":0}